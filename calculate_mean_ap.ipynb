{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def cxcywh2xyxy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2]/2  # x center\n",
    "    y[..., 1] = x[..., 1] - x[..., 3]/2  # y center\n",
    "    y[..., 2] = x[..., 0] + x[..., 2]/2  # width\n",
    "    y[..., 3] = x[..., 1] + x[..., 3]/2  # height\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesPath = \"*RPC/test/images/*.png\"\n",
    "labelsPath = \"*RPC/test/labels/*.txt\"\n",
    "SupportPath = \"RPC/support/images/\"\n",
    "best = 'runs/oneshot/yolov8n_RPC/weights/best.pt'\n",
    "\n",
    "# imagesPath = \"*COCO1/valid/images/*.png\"\n",
    "# labelsPath = \"*COCO1/valid/labels/*.txt\"\n",
    "# SupportPath = \"COCO1/support/images/\"\n",
    "# best = 'runs/oneshot/yolov8n_COCO1__support0/weights/best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37655\n",
      "37655\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "filesName =  glob.glob(imagesPath)\n",
    "filesName.sort()\n",
    "labelsName = glob.glob(labelsPath)\n",
    "labelsName.sort()\n",
    "print(len(filesName))\n",
    "print(len(labelsName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "model = YOLO(best)  # load a pretrained YOLOv8n model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37655/37655 [14:34<00:00, 43.04it/s]\n"
     ]
    }
   ],
   "source": [
    "true_labels = {}\n",
    "predictions = {}\n",
    "# i = 0\n",
    "\n",
    "for f,l in tqdm(zip(filesName,labelsName), total=len(filesName)):\n",
    "    name = f.split('.')[0]\n",
    "    classe = f.split('.')[1]\n",
    "\n",
    "    image = Image.open(f)\n",
    "    image = np.asarray(image)\n",
    "    support = Image.open(SupportPath+classe+'.png')\n",
    "    support = np.asarray(support)\n",
    "\n",
    "    #convert GrayImage to RGB Image:\n",
    "    if(len(image.shape) == 2):\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "\n",
    "    results = model.predict(source=image, support=support, verbose=False)  # predict on an image\n",
    "\n",
    "    bboxes = results[0].boxes.data.cpu().numpy()\n",
    "    if bboxes.ndim == 1:\n",
    "        bboxes = np.array([bboxes])\n",
    "    bboxes[:,5] = int(f.split('.')[1])\n",
    "    bboxes[:,:4] = bboxes[:,:4]/results[0].orig_img.shape[0]\n",
    "\n",
    "    label = np.loadtxt(l)\n",
    "    if label.ndim == 1:\n",
    "        label = np.array([label])\n",
    "    label[:,0] = int(f.split('.')[1])\n",
    "\n",
    "    label[:,1:5] = cxcywh2xyxy(label[:,1:5])\n",
    "\n",
    "    if classe not in true_labels.keys():\n",
    "        predictions[classe] = {name:np.array(bboxes)}\n",
    "        true_labels[classe] = {name:np.array(label)}\n",
    "    else:\n",
    "        if name not in predictions[classe]:\n",
    "            predictions[classe][name] = np.array(bboxes)\n",
    "            true_labels[classe][name] = np.array(label)\n",
    "        if len(bboxes) != 0:\n",
    "           predictions[classe][name] = np.concatenate((predictions[classe][name],bboxes),0)\n",
    "        true_labels[classe][name] = np.concatenate((true_labels[classe][name],label),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "COLORS = [\n",
    "    '#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c',\n",
    "    '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5',\n",
    "    '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f',\n",
    "    '#c7c7c7', '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n",
    "\n",
    "\n",
    "def calc_iou_individual(pred_box, gt_box):\n",
    "    \"\"\"Calculate IoU of single predicted and ground truth box\n",
    "    Args:\n",
    "        pred_box (list of floats): location of predicted object as\n",
    "            [xmin, ymin, xmax, ymax]\n",
    "        gt_box (list of floats): location of ground truth object as\n",
    "            [xmin, ymin, xmax, ymax]\n",
    "    Returns:\n",
    "        float: value of the IoU for the two boxes.\n",
    "    Raises:\n",
    "        AssertionError: if the box is obviously malformed\n",
    "    \"\"\"\n",
    "    c, x1_t, y1_t, x2_t, y2_t = gt_box\n",
    "    x1_p, y1_p, x2_p, y2_p = pred_box\n",
    "\n",
    "    if (x1_p > x2_p) or (y1_p > y2_p):\n",
    "        raise AssertionError(\n",
    "            \"Prediction box is malformed? pred box: {}\".format(pred_box))\n",
    "    if (x1_t > x2_t) or (y1_t > y2_t):\n",
    "        raise AssertionError(\n",
    "            \"Ground Truth box is malformed? true box: {}\".format(gt_box))\n",
    "\n",
    "    if (x2_t < x1_p or x2_p < x1_t or y2_t < y1_p or y2_p < y1_t):\n",
    "        return 0.0\n",
    "\n",
    "    far_x = np.min([x2_t, x2_p])\n",
    "    near_x = np.max([x1_t, x1_p])\n",
    "    far_y = np.min([y2_t, y2_p])\n",
    "    near_y = np.max([y1_t, y1_p])\n",
    "\n",
    "    inter_area = (far_x - near_x + 1) * (far_y - near_y + 1)\n",
    "    true_box_area = (x2_t - x1_t + 1) * (y2_t - y1_t + 1)\n",
    "    pred_box_area = (x2_p - x1_p + 1) * (y2_p - y1_p + 1)\n",
    "    iou = inter_area / (true_box_area + pred_box_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "def box_iou(box1, box2, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Calculate intersection-over-union (IoU) of boxes.\n",
    "    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n",
    "    Based on https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n",
    "    \"\"\"\n",
    "\n",
    "    (a1, a2), (b1, b2) = box1.unsqueeze(1).chunk(2, 2), box2.unsqueeze(0).chunk(2, 2)\n",
    "    inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp_(0).prod(2)\n",
    "\n",
    "    # IoU = inter / (area1 + area2 - inter)\n",
    "    return inter / ((a2 - a1).prod(2) + (b2 - b1).prod(2) - inter + eps)\n",
    "\n",
    "def get_single_image_results(gt_boxes, pred_boxes, iou_thr):\n",
    "    \"\"\"Calculates number of true_pos, false_pos, false_neg from single batch of boxes.\n",
    "    Args:\n",
    "        gt_boxes (list of list of floats): list of locations of ground truth\n",
    "            objects as [xmin, ymin, xmax, ymax]\n",
    "        pred_boxes (dict): dict of dicts of 'boxes' (formatted like `gt_boxes`)\n",
    "            and 'scores'\n",
    "        iou_thr (float): value of IoU to consider as threshold for a\n",
    "            true prediction.\n",
    "    Returns:\n",
    "        dict: true positives (int), false positives (int), false negatives (int)\n",
    "    \"\"\"\n",
    "\n",
    "    all_pred_indices = range(len(pred_boxes))\n",
    "    all_gt_indices = range(len(gt_boxes))\n",
    "    if len(all_pred_indices) == 0:\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = len(gt_boxes)\n",
    "        return {'true_pos': tp, 'false_pos': fp, 'false_neg': fn}\n",
    "    if len(all_gt_indices) == 0:\n",
    "        tp = 0\n",
    "        fp = len(pred_boxes)\n",
    "        fn = 0\n",
    "        return {'true_pos': tp, 'false_pos': fp, 'false_neg': fn}\n",
    "\n",
    "    gt_idx_thr = []\n",
    "    pred_idx_thr = []\n",
    "    ious = []\n",
    "    for ipb, pred_box in enumerate(pred_boxes):\n",
    "        for igb, gt_box in enumerate(gt_boxes):\n",
    "            iou = calc_iou_individual(pred_box, gt_box)\n",
    "            if iou > iou_thr:\n",
    "                gt_idx_thr.append(igb)\n",
    "                pred_idx_thr.append(ipb)\n",
    "                ious.append(iou)\n",
    "\n",
    "    args_desc = np.argsort(ious)[::-1]\n",
    "    if len(args_desc) == 0:\n",
    "        # No matches\n",
    "        tp = 0\n",
    "        fp = len(pred_boxes)\n",
    "        fn = len(gt_boxes)\n",
    "    else:\n",
    "        gt_match_idx = []\n",
    "        pred_match_idx = []\n",
    "        for idx in args_desc:\n",
    "            gt_idx = gt_idx_thr[idx]\n",
    "            pr_idx = pred_idx_thr[idx]\n",
    "            # If the boxes are unmatched, add them to matches\n",
    "            if (gt_idx not in gt_match_idx) and (pr_idx not in pred_match_idx):\n",
    "                gt_match_idx.append(gt_idx)\n",
    "                pred_match_idx.append(pr_idx)\n",
    "        tp = len(gt_match_idx)\n",
    "        fp = len(pred_boxes) - len(pred_match_idx)\n",
    "        fn = len(gt_boxes) - len(gt_match_idx)\n",
    "\n",
    "    return {'true_pos': tp, 'false_pos': fp, 'false_neg': fn}\n",
    "\n",
    "def calc_precision_recall(img_results):\n",
    "    \"\"\"Calculates precision and recall from the set of images\n",
    "    Args:\n",
    "        img_results (dict): dictionary formatted like:\n",
    "            {\n",
    "                'img_id1': {'true_pos': int, 'false_pos': int, 'false_neg': int},\n",
    "                'img_id2': ...\n",
    "                ...\n",
    "            }\n",
    "    Returns:\n",
    "        tuple: of floats of (precision, recall)\n",
    "    \"\"\"\n",
    "    true_pos = 0; false_pos = 0; false_neg = 0\n",
    "    for _, res in img_results.items():\n",
    "        true_pos += res['true_pos']\n",
    "        false_pos += res['false_pos']\n",
    "        false_neg += res['false_neg']\n",
    "\n",
    "    try:\n",
    "        precision = true_pos/(true_pos + false_pos)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0.0\n",
    "    try:\n",
    "        recall = true_pos/(true_pos + false_neg)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0.0\n",
    "\n",
    "    return (precision, recall)\n",
    "\n",
    "def get_model_scores_map(pred_boxes):\n",
    "    \"\"\"Creates a dictionary of from model_scores to image ids.\n",
    "    Args:\n",
    "        pred_boxes (dict): dict of dicts of 'boxes' and 'scores'\n",
    "    Returns:\n",
    "        dict: keys are model_scores and values are image ids (usually filenames)\n",
    "    \"\"\"\n",
    "    model_scores_map = {}\n",
    "    for img_id, val in pred_boxes.items():\n",
    "        if len(val) == 0:\n",
    "            continue\n",
    "        for score in val[:,4]:\n",
    "            if score not in model_scores_map.keys():\n",
    "                model_scores_map[score] = [img_id]\n",
    "            else:\n",
    "                model_scores_map[score].append(img_id)\n",
    "    return model_scores_map\n",
    "\n",
    "def get_avg_precision_at_iou(gt_boxes, pred_boxes, iou_thr=0.5):\n",
    "    \"\"\"Calculates average precision at given IoU threshold.\n",
    "    Args:\n",
    "        gt_boxes (list of list of floats): list of locations of ground truth\n",
    "            objects as [xmin, ymin, xmax, ymax]\n",
    "        pred_boxes (list of list of floats): list of locations of predicted\n",
    "            objects as [xmin, ymin, xmax, ymax]\n",
    "        iou_thr (float): value of IoU to consider as threshold for a\n",
    "            true prediction.\n",
    "    Returns:\n",
    "        dict: avg precision as well as summary info about the PR curve\n",
    "        Keys:\n",
    "            'avg_prec' (float): average precision for this IoU threshold\n",
    "            'precisions' (list of floats): precision value for the given\n",
    "                model_threshold\n",
    "            'recall' (list of floats): recall value for given\n",
    "                model_threshold\n",
    "            'models_thrs' (list of floats): model threshold value that\n",
    "                precision and recall were computed for.\n",
    "    \"\"\"\n",
    "    model_scores_map = get_model_scores_map(pred_boxes)\n",
    "    sorted_model_scores = sorted(model_scores_map.keys())\n",
    "\n",
    "    # Sort the predicted boxes in descending order (lowest scoring boxes first):\n",
    "    for img_id in pred_boxes.keys():\n",
    "        arg_sort = np.argsort(pred_boxes[img_id][:,4])\n",
    "        if(len(pred_boxes[img_id]) == 0):\n",
    "            continue\n",
    "        pred_boxes[img_id] = np.array(pred_boxes[img_id][arg_sort])\n",
    "\n",
    "    pred_boxes_pruned = deepcopy(pred_boxes)\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    model_thrs = []\n",
    "    img_results = {}\n",
    "    # Loop over model score thresholds and calculate precision, recall\n",
    "    for ithr, model_score_thr in enumerate(sorted_model_scores[:-1]):\n",
    "        # On first iteration, define img_results for the first time:\n",
    "        img_ids = gt_boxes.keys() if ithr == 0 else model_scores_map[model_score_thr]\n",
    "        for img_id in img_ids:\n",
    "            gt_boxes_img = gt_boxes[img_id]\n",
    "            box_scores = pred_boxes_pruned[img_id][:,4]\n",
    "            start_idx = 0\n",
    "            for score in box_scores:\n",
    "                if score <= model_score_thr:\n",
    "                    pred_boxes_pruned[img_id]\n",
    "                    start_idx += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # Remove boxes, scores of lower than threshold scores:\n",
    "            pred_boxes_pruned[img_id] =  np.array(pred_boxes_pruned[img_id][start_idx:])\n",
    "\n",
    "            # Recalculate image results for this image\n",
    "            img_results[img_id] = get_single_image_results(\n",
    "                gt_boxes_img, pred_boxes_pruned[img_id][:,:4], iou_thr)\n",
    "\n",
    "        prec, rec = calc_precision_recall(img_results)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        model_thrs.append(model_score_thr)\n",
    "\n",
    "    precisions = np.array(precisions)\n",
    "    recalls = np.array(recalls)\n",
    "    prec_at_rec = []\n",
    "    for recall_level in np.linspace(0.0, 1.0, 11):\n",
    "        try:\n",
    "            args = np.argwhere(recalls >= recall_level).flatten()\n",
    "            prec = max(precisions[args])\n",
    "        except ValueError:\n",
    "            prec = 0.0\n",
    "        prec_at_rec.append(prec)\n",
    "    avg_prec = np.mean(prec_at_rec)\n",
    "\n",
    "    return {\n",
    "        'avg_prec': avg_prec,\n",
    "        'precisions': precisions,\n",
    "        'recalls': recalls,\n",
    "        'model_thrs': model_thrs}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe 131\n",
      "Single IoU calculation took 0.0102 secs\n",
      "avg precision: 0.0202\n",
      "classe 100\n",
      "Single IoU calculation took 0.0652 secs\n",
      "avg precision: 0.1229\n",
      "classe 45\n",
      "Single IoU calculation took 0.3460 secs\n",
      "avg precision: 0.1878\n",
      "classe 130\n",
      "Single IoU calculation took 0.1224 secs\n",
      "avg precision: 0.0251\n",
      "classe 94\n",
      "Single IoU calculation took 0.0099 secs\n",
      "avg precision: 0.0327\n",
      "classe 124\n",
      "Single IoU calculation took 0.0059 secs\n",
      "avg precision: 0.0909\n",
      "classe 57\n",
      "Single IoU calculation took 0.7287 secs\n",
      "avg precision: 0.7431\n",
      "classe 62\n",
      "Single IoU calculation took 0.0487 secs\n",
      "avg precision: 0.1693\n",
      "classe 170\n",
      "Single IoU calculation took 0.0303 secs\n",
      "avg precision: 0.0818\n",
      "classe 99\n",
      "Single IoU calculation took 0.3934 secs\n",
      "avg precision: 0.7170\n",
      "classe 116\n",
      "Single IoU calculation took 0.0168 secs\n",
      "avg precision: 0.0376\n",
      "classe 183\n",
      "Single IoU calculation took 0.1384 secs\n",
      "avg precision: 0.4741\n",
      "classe 89\n",
      "Single IoU calculation took 0.1599 secs\n",
      "avg precision: 0.2559\n",
      "classe 12\n",
      "Single IoU calculation took 0.9782 secs\n",
      "avg precision: 0.7718\n",
      "classe 156\n",
      "Single IoU calculation took 0.2146 secs\n",
      "avg precision: 0.1868\n",
      "classe 51\n",
      "Single IoU calculation took 0.2157 secs\n",
      "avg precision: 0.7010\n",
      "classe 154\n",
      "Single IoU calculation took 4.4137 secs\n",
      "avg precision: 0.6336\n",
      "classe 3\n",
      "Single IoU calculation took 0.0865 secs\n",
      "avg precision: 0.3563\n",
      "classe 163\n",
      "Single IoU calculation took 0.6084 secs\n",
      "avg precision: 0.7695\n",
      "classe 109\n",
      "Single IoU calculation took 0.2447 secs\n",
      "avg precision: 0.3043\n",
      "classe 50\n",
      "Single IoU calculation took 0.4802 secs\n",
      "avg precision: 0.2070\n",
      "classe 30\n",
      "Single IoU calculation took 1.6152 secs\n",
      "avg precision: 0.7299\n",
      "classe 18\n",
      "Single IoU calculation took 2.3455 secs\n",
      "avg precision: 0.6861\n",
      "classe 95\n",
      "Single IoU calculation took 0.8214 secs\n",
      "avg precision: 0.8076\n",
      "classe 26\n",
      "Single IoU calculation took 0.3117 secs\n",
      "avg precision: 0.4348\n",
      "classe 162\n",
      "Single IoU calculation took 0.6085 secs\n",
      "avg precision: 0.7157\n",
      "classe 74\n",
      "Single IoU calculation took 0.7398 secs\n",
      "avg precision: 0.8853\n",
      "classe 67\n",
      "Single IoU calculation took 0.0768 secs\n",
      "avg precision: 0.0455\n",
      "classe 41\n",
      "Single IoU calculation took 0.4239 secs\n",
      "avg precision: 0.8292\n",
      "classe 112\n",
      "Single IoU calculation took 0.0374 secs\n",
      "avg precision: 0.0455\n",
      "classe 200\n",
      "Single IoU calculation took 0.3395 secs\n",
      "avg precision: 0.5630\n",
      "classe 150\n",
      "Single IoU calculation took 0.3199 secs\n",
      "avg precision: 0.5050\n",
      "classe 174\n",
      "Single IoU calculation took 1.3202 secs\n",
      "avg precision: 0.5533\n",
      "classe 9\n",
      "Single IoU calculation took 0.0179 secs\n",
      "avg precision: 0.0795\n",
      "classe 133\n",
      "Single IoU calculation took 0.2566 secs\n",
      "avg precision: 0.3786\n",
      "classe 17\n",
      "Single IoU calculation took 1.3269 secs\n",
      "avg precision: 0.8515\n",
      "classe 65\n",
      "Single IoU calculation took 0.0301 secs\n",
      "avg precision: 0.0909\n",
      "classe 192\n",
      "Single IoU calculation took 0.2786 secs\n",
      "avg precision: 0.0397\n",
      "classe 61\n",
      "Single IoU calculation took 0.1485 secs\n",
      "avg precision: 0.1775\n",
      "classe 103\n",
      "Single IoU calculation took 0.0670 secs\n",
      "avg precision: 0.1474\n"
     ]
    }
   ],
   "source": [
    "gt_boxes = true_labels\n",
    "pred_boxes = predictions\n",
    "\n",
    "liste = {}\n",
    "\n",
    "# Runs it for one IoU threshold\n",
    "iou_thr = 0.5\n",
    "\n",
    "for c in gt_boxes.keys():\n",
    "    start_time = time.time()\n",
    "    data = get_avg_precision_at_iou(true_labels[c], predictions[c], iou_thr=iou_thr)\n",
    "    end_time = time.time()\n",
    "    print(\"classe \"+str(c))\n",
    "    print('Single IoU calculation took {:.4f} secs'.format(end_time - start_time))\n",
    "    print('avg precision: {:.4f}'.format(data['avg_prec']))\n",
    "    liste[c] = data['avg_prec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0,len(liste.keys()))\n",
    "y = liste.values()\n",
    "\n",
    "plt.bar(x,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3863664274537153"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
