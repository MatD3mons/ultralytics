{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def cxcywh2xyxy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2]/2  # x center\n",
    "    y[..., 1] = x[..., 1] - x[..., 3]/2  # y center\n",
    "    y[..., 2] = x[..., 0] + x[..., 2]/2  # width\n",
    "    y[..., 3] = x[..., 1] + x[..., 3]/2  # height\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesPath = \"*RPC/test/images/*.png\"\n",
    "labelsPath = \"*RPC/test/labels/*.txt\"\n",
    "SupportPath = \"RPC/support/images/\"\n",
    "best = 'runs/oneshot/yolov8n_RPC/weights/best.pt'\n",
    "\n",
    "# imagesPath = \"*COCO1/valid/images/*.png\"\n",
    "# labelsPath = \"*COCO1/valid/labels/*.txt\"\n",
    "# SupportPath = \"COCO1/support/images/\"\n",
    "# best = 'runs/oneshot/yolov8n_COCO1__support0/weights/best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filesName =  glob.glob(imagesPath)\n",
    "filesName.sort()\n",
    "labelsName = glob.glob(labelsPath)\n",
    "labelsName.sort()\n",
    "print(len(filesName))\n",
    "print(len(labelsName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "model = YOLO(best)  # load a pretrained YOLOv8n model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "predictions = []\n",
    "  \n",
    "for f,l in tqdm(zip(filesName,labelsName), total=len(filesName)):\n",
    "    assert f.split('/')[-1][:-4] == l.split('/')[-1][:-4] \n",
    "\n",
    "    image = cv2.imread(f)\n",
    "\n",
    "    data = pd.read_csv(l, header = None, delimiter=' ')\n",
    "    cls = data[0].unique()\n",
    "\n",
    "    pred_boxes = []\n",
    "    pred_scores = []\n",
    "    pred_labels = []\n",
    "\n",
    "    true_boxes = []\n",
    "    true_labels = []\n",
    "\n",
    "    for c in cls:\n",
    "\n",
    "        support = cv2.imread(SupportPath+str(c)+'.png')\n",
    "\n",
    "        results = model.predict(source=image, support=support, verbose=False)  # predict on an image\n",
    "\n",
    "        bboxes = results[0].boxes.data.cpu().numpy()\n",
    "\n",
    "        if len(bboxes) != 0:\n",
    "            bboxes[:,5] = c\n",
    "            if bboxes.ndim == 1:\n",
    "                bboxes = np.array([bboxes])\n",
    "            bboxes[:,:4] = bboxes[:,:4]/results[0].orig_img.shape[0]\n",
    "            for b,s,l in zip(bboxes[:,:4],bboxes[:,4],bboxes[:,5]):\n",
    "                pred_boxes.append(b)\n",
    "                pred_scores.append(s)\n",
    "                pred_labels.append(l)\n",
    "\n",
    "\n",
    "        label = data.to_numpy()[:,:5]\n",
    "        label = label[np.where(label[:,0] == c)]\n",
    "        label[:,1:5] = cxcywh2xyxy(label[:,1:5])\n",
    "\n",
    "        for b,l in zip(label[:,1:5],label[:,0]):\n",
    "            true_boxes.append(b)\n",
    "            true_labels.append(l)\n",
    "\n",
    "    true_boxes = np.array(true_boxes)\n",
    "    true_labels = np.array(true_labels)\n",
    "    pred_boxes = np.array(pred_boxes)\n",
    "    pred_scores = np.array(pred_scores)\n",
    "    pred_labels = np.array(pred_labels)\n",
    "\n",
    "    predictions.append(\n",
    "        dict(\n",
    "            boxes=torch.as_tensor(pred_boxes),\n",
    "            scores=torch.as_tensor(pred_scores),\n",
    "            labels=torch.as_tensor(pred_labels, dtype=torch.int32),\n",
    "            )\n",
    "        )       \n",
    "    \n",
    "    target.append(\n",
    "        dict(\n",
    "            boxes=torch.as_tensor(true_boxes),\n",
    "            labels=torch.as_tensor(true_labels, dtype=torch.int32).reshape(-1),\n",
    "            )\n",
    "        )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(t,p, image):\n",
    "    img = np.copy(image)\n",
    "    # Blue color in BGR\n",
    "    color = (255, 0, 0)\n",
    "  \n",
    "    # Line thickness of 2 px\n",
    "    thickness = 2   \n",
    "    for x1,y1,x2,y2 in t['boxes']*640:\n",
    "        cv2.rectangle(img, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness)\n",
    "\n",
    "    # Green color in BGR\n",
    "    color = (0, 255, 0)\n",
    "  \n",
    "    # Line thickness of 2 px\n",
    "    thickness = 2   \n",
    "    for x1,y1,x2,y2 in p['boxes']*640:\n",
    "        cv2.rectangle(img, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7\n",
    "\n",
    "f = filesName[index]\n",
    "image = Image.open(f)\n",
    "plot(target[index],predictions[index],image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "preds = predictions\n",
    "target = target\n",
    "metric = MeanAveragePrecision()\n",
    "metric.update(preds, target)\n",
    "print(metric.compute())\n",
    "# fig_, ax_ = metric.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import tensor\n",
    "# from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "# preds = [dict(\n",
    "#      boxes=tensor([[0.0, 0.0, 100.0, 100.0]]),\n",
    "#     scores=tensor([0.8]),\n",
    "#      labels=tensor([0]),\n",
    "#  ),dict(\n",
    "#      boxes=tensor([[0.0, 0.0, 100.0, 100.0]]),\n",
    "#     scores=tensor([0.8]),\n",
    "#      labels=tensor([0]),\n",
    "#  )]\n",
    "# target = [dict(\n",
    "#      boxes=tensor([[0.0, 0.0, 110.0, 110.0]]),\n",
    "#      labels=tensor([0]),\n",
    "#  ),dict(\n",
    "#      boxes=tensor([[0.0, 0.0, 110.0, 110.0]]),\n",
    "#      labels=tensor([0]),\n",
    "#  )]\n",
    "\n",
    "# print(preds)\n",
    "\n",
    "# print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = MeanAveragePrecision()\n",
    "# metric.update(preds, target)\n",
    "# print(metric.compute())\n",
    "# fig_, ax_ = metric.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
